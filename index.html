<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8GF920BBNG"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-8GF920BBNG');
</script>
 
  <title>Wen-Tse Chen</title>
  
  <meta name="author" content="Wen-Tse Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
	
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Wen-Tse Chen Èô≥ÊñáÊæ§</name>
              </p>
              <p>
				I am a first year PhD student at <a href="https://www.ri.cmu.edu">Carnegie Mellon University (Robotics Institute)</a> advised by Prof. <a href="https://www.cs.cmu.edu/~schneide/">Jeff Schneider</a>. 
				Prior to this, I pursued my undergraduate studies in Automation at <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>, 
				where I had the privilege of working alongside Prof. <a href="https://ml.cs.tsinghua.edu.cn/~jun/index.shtml">Jun Zhu</a>. 
			  </p>
			  <p>
				I am always open to new research collaborations. Please feel free to reach out if our interests align.
			  </p>
              <p style="text-align:center">
                <a href="mailto:chenwenze21@gmail.com">Email</a> &nbsp/&nbsp
                <!-- <a href="data/resume.pdf">CV</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com.tw/citations?user=VSUDQ0oAAAAJ&hl=zh-TW">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/WentseChen">Github</a>
              </p>
              <p>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/wentsechen_circle.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/wentsechen_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests focus on LLM agents, deep reinforcement learning, and their applications in decision-making and robotics.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>		

		
		  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/verlog.gif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://wentsechen.github.io/Verlog_blogpost">
                <papertitle>Verlog: A Multi-turn RL framework for LLM agents</papertitle>
              </a>
		    
              <br>
              <b>Wen-Tse Chen</b>, 
              Jiayu Chen,
              Hao Zhu,
              Jeff Schneider,
              <br>
	      <p></p>
              <p>
                Proposed a multi-turn reinforcement learning framework built for long-horizon LLM-agentic tasks with highly variable episode lengths.
              </p>
            </td>
          </tr>
		  
<!--           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/robotics.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2503.18221">
                <papertitle>Decentralized Navigation of a Cable-Towed Load using Quadrupedal Robot Team via MARL</papertitle>
              </a>
		    
              <br>
              <b>Wen-Tse Chen*</b>, 
              Minh Nguyen*,
              Zhongyu Li*,
              Guo Ning Sue,
              Koushil Sreenath
              <br>
	      <p></p>
              <p>
                Proposed a scalable, decentralized MARL-based system for coordinating a team of quadrupedal robots to collaboratively tow a cable-connected load through cluttered environments, ensuring flexibility, scalability, and robustness across varying team sizes and environmental conditions.
              </p>
            </td>
          </tr> -->
		
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/BabyAI.gif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/pdf?id=QAVpe6a3rp">
                <papertitle>Retrospective In-Context Learning for Temporal Credit Assignment with Large Language Models</papertitle>
              </a>
		    
              <br>
              <b>Wen-Tse Chen</b>, 
              Jiayu Chen, 
              Fahim Tajwar,
              Hao Zhu,
              Xintong Duan,
              Russ Salakhutdinov, 
              Jeff Schneider
              <br>
	      
              <em>NeurIPS 2025</em><br>
              <!-- <em>NeurIPS Adaptive Foundation Models Workshop, 2024 <span style="color:red">(Oral presentation)</span></em>  -->
				
	      <p></p>
              <p>
                Presented a sample-efficient method for online fine-tuning LLM agents by using in-context learning to convert sparse feedback into dense signals, enabling LLMs to adapt to dynamic environments with minimal data.
              </p>
            </td>
          </tr>
		
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/soft_qmix.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2406.13930">
                <papertitle>ME-IGM: Individual-Global-Max in Maximum Entropy Multi-Agent Reinforcement Learning</papertitle>
              </a>
		
              <br>
              <b>Wen-Tse Chen</b>, 
		      Yuxuan Li,
		      Shiyu Huang,
		      Jiayu Chen,
		      Jeff Schneider,
              <br>
				
              <em>AAMAS 2026</em><br>
	      
	      <p></p>
              <p>
		      Enhanced IGM-based algorithms with maximum entropy RL for better exploration, ensuring locally optimal actions match global optima via an order preserving transformation, achieving SOTA performance on SAMC-v2 and Overcooked benchmark.
              </p>
            </td>
          </tr>	
		
<!--           <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/openrl.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/OpenRL-Lab/openrl">
                <papertitle>OpenRL: an open-source reinforcement learning research framework</papertitle>
              </a>
		
              <br>
	      Shiyu Huang, 
              <b>Wen-Tse Chen</b>, 
              Yiwen Sun, 
	      Fuqing Bie, 
	      Wei-Wei Tu
              <br>
	      
	      <iframe src="https://ghbtns.com/github-btn.html?user=OpenRL-Lab&repo=openrl&type=star&count=true" frameborder="0" scrolling="0" width="170" height="30" title="GitHub"></iframe>
              <p></p>
              <p>
		      An open source framework supports single-agent RL, multi-agent RL, RLHF, and self-play training.
              </p>
            </td>
          </tr>			 -->
		  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Spread(easy).gif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2207.05631">
                <papertitle>DGPO: Discovering Multiple Strategies with Diversity-Guided Policy Optimization</papertitle>
              </a>
		    
              <br>
              <b>Wen-Tse Chen</b>, 
              Shiyu Huang, 
              Yuan Chiang, 
	      Tim Pearce,
	      Wei-Wei Tu,
	      Chen Ting, 
              Zhu Jun,
              <br>
              <em>AAAI 2024</em> 
              <p></p>
              <p>
                Proposed an on-policy framework for discovering multiple diverse optimal strategies for the same task in a single training process.
              </p>
            </td>
          </tr>

<!-- 		<tr>
            <td rowspan="2" style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/tikick.gif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2302.07515">
                <papertitle>TiZero: Mastering Multi-Agent Football with Curriculum Learning and Self-Play</papertitle>
              </a>
	      <br> 
              Fanqi Lin*, 
	      Shiyu Huang*,
	      Tim Pearce,
              <b>Wen-Tse Chen</b>,
              Wei-Wei Tu
              <br>
	      <em>The 22nd International Conference on Autonomous Agents and Multiagent Systems(AAMAS2023)</em>
              <p></p>
              <p>
		      Created an on-policy MARL algorithm, along with an adaptive curriculum learning approach and a unique self-play strategy, for excelling in the Google Research Football game.
              </p>
            </td>
        </tr>	 -->
		
<!-- 		<tr>
	    	<td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/tikick.gif' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2110.04507">
                <papertitle>TiKick: Towards Playing Multi-agent Football Full Games from Single-agent Demonstrations</papertitle>
              </a>
	      <br> 
              Shiyu Huang*, 
              <b>Wen-Tse Chen*</b>,
              Longfei Zhang, 
	      Shizhen Xu, 
	      Ziyang Li, 
	      Fengming Zhu, 
	      Deheng Ye, 
	      Ting Chen, 
	      Jun Zhu
              <br>
	      <em>NeurIPS-21 Workshop: 2nd Offline Reinforcement Learning Workshop</em>
              <p></p>
              <p>
                Developed a distributed learning system and new offline algorithms to learn a powerful multi-agent AI from the fixed single-agent dataset.
              </p>
            </td>
          </tr>		 -->
        
        </tbody></table>
	
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<tr>
			<td style="padding:0px">
			<p style="text-align:right;font-size:small;">
			last update: Feb 2026
			</p>
			</td>
		</tr>
		<tr>
			<td style="padding:0px">
			<p style="text-align:right;font-size:small;">
			Copy from <a href="https://jonbarron.info/">Dr. Jon Barron</a>'s page.
			</p>
			</td>
		</tr>
	</tbody></table>	
</body>

</html>
